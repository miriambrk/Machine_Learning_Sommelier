{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Files can be found here:\n",
    "\n",
    "https://www.kaggle.com/zynicide/wine-reviews\n",
    "The dataset was scraped from WineEnthusiest.\n",
    "\n",
    "The file used is:\n",
    "\n",
    "winemag-data_first150k.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read in the wine review data, view the data to make sure it appeared\n",
    "sommData = pd.read_csv('Data/winemag-data_first150k.csv')\n",
    "sommData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# trim the data to remove the unnamed column\n",
    "sommData = sommData[sommData.columns[1:11]]\n",
    "sommData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# replace NaN with XXXXX for each  string based column\n",
    "stringColList = [\"country\", \"description\", \"designation\", \"province\", \"region_1\", \"region_2\", \"variety\", \"winery\"]\n",
    "for col in stringColList:\n",
    "    sommData[col].fillna(\"none\", inplace=True)\n",
    "    \n",
    "sommData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# replace Nan with 0 for number based columns\n",
    "numColList = [\"points\", \"price\"]\n",
    "for col in numColList:\n",
    "    sommData[col].fillna(0, inplace=True)\n",
    "    \n",
    "sommData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove dupes\n",
    "dups = sommData[sommData.duplicated('description')]\n",
    "sommData = sommData.drop_duplicates(subset='description')\n",
    "print('Total unique reviews:', len(sommData))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove varities with only 1 description\n",
    "counts = sommData['variety'].value_counts()\n",
    "sommData= sommData[sommData['variety'].isin(counts[counts > 3].index)]\n",
    "sommData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create the X and y values\n",
    "X = sommData[\"description\"]\n",
    "y = sommData[\"variety\"]\n",
    "\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "# split the data into train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)\n",
    "\n",
    "\n",
    "# vectorize the description data\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "vectorizer.fit(X_train)\n",
    "joblib.dump(vectorizer, 'vectorizer.pkl') \n",
    "X_train_vec = vectorizer.transform(X_train)\n",
    "\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "# Step 1: Label-encode data set\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "joblib.dump(label_encoder, 'label_encoder.pkl') \n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)\n",
    "\n",
    "# Step 2: Convert encoded labels to one-hot-encoding\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)\n",
    "\n",
    "print(y_test_categorical.shape, y_train_categorical.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create Deep Learning Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=750, activation='relu', input_dim=X_train_vec.shape[1]))\n",
    "#model.add(Dense(units=50, activation='relu'))\n",
    "model.add(Dense(units=364, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compile the model and fit it\n",
    "model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "model.fit(\n",
    "    X_train_vec,\n",
    "    y_train_categorical,\n",
    "    epochs=10,\n",
    "    shuffle=True,\n",
    "    verbose=364\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_loss, model_accuracy = model.evaluate(X_test_vec, y_test_categorical, verbose=364)\n",
    "print(f\"Normal Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test the data\n",
    "encoded_predictions = model.predict_classes(X_test_vec[100:105])\n",
    "prediction_labels = label_encoder.inverse_transform(encoded_predictions)\n",
    "print(f\"Predicted classes: {prediction_labels}\")\n",
    "print(f\"Actual Labels: {list(y_train[100:105])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the model\n",
    "model.save(\"ML_Somm.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the saved model\n",
    "from keras.models import load_model\n",
    "model = load_model(\"ML_Somm.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# code to run user input \n",
    "test = [\"Currant, Plum, Black Cherry & Spice, with notes of Olive, Vanilla Mint, Tobacco, Toasty Cedar, Anise, Pepper & Herbs\"]\n",
    "test_vec = vectorizer.transform(test)\n",
    "encoded_test = model.predict_classes(test_vec)\n",
    "predict_lable = label_encoder.inverse_transform(encoded_test)\n",
    "print(predict_lable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the saved model\n",
    "from keras.models import load_model\n",
    "model = load_model(\"ML_Somm.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code required for the twitter bot:\n",
    "import boto3\n",
    "import botocore\n",
    "\n",
    "BUCKET_NAME = 'mlsomm' # replace with your bucket name\n",
    "KEY = 'ML_Somm.h5' # replace with your object key\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "\n",
    "try:\n",
    "    s3.Bucket(BUCKET_NAME).download_file(KEY, 'somm_model.h5')\n",
    "except botocore.exceptions.ClientError as e:\n",
    "    if e.response['Error']['Code'] == \"404\":\n",
    "        print(\"The object does not exist.\")\n",
    "    else:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Red Blend']\n"
     ]
    }
   ],
   "source": [
    "# code required for the twitter bot:\n",
    "\n",
    "# import dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "vectorizer = joblib.load('vectorizer.pkl')\n",
    "label_encoder = joblib.load('label_encoder.pkl') \n",
    "\n",
    "\n",
    "\n",
    "# load the model\n",
    "model = load_model(\"somm_model.h5\")\n",
    "# model = load_model(\"ML_Somm.h5\")\n",
    "\n",
    "# test the data\n",
    "test = [\"Currant, Plum, Black Cherry & Spice, with notes of Olive, Vanilla Mint, Tobacco, Toasty Cedar, Anise, Pepper & Herbs\"]\n",
    "test_vec = vectorizer.transform(test)\n",
    "encoded_test = model.predict_classes(test_vec)\n",
    "predict_label = label_encoder.inverse_transform(encoded_test)\n",
    "print(predict_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonData]",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
